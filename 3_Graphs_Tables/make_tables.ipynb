{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55e0c3e",
   "metadata": {},
   "source": [
    "# make_tables.ipynb\n",
    "**Purpose:** Generate LaTeX tables used in the manuscript (e.g., tuned hyperparameters, feature rankings, thresholds).  \n",
    "**Inputs:** Excel/CSV outputs from Stage 1 and Stage 2 tuning scripts.  \n",
    "**Outputs:** LaTeX `.txt` table files.\n",
    "\n",
    "**Part of repository:** `3_Graphs_Tables`  \n",
    "**Reproducibility:** This notebook is deterministic given the provided model output files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f251f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from make_outputs import format_label, load_selected_models\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdd7c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBREDDIT_LABELS = {\n",
    "    \"conspiracy\": \"r/Conspiracy\",\n",
    "    \"crypto\": \"r/CryptoCurrency\",\n",
    "    \"politics\": \"r/politics\",\n",
    "}\n",
    "\n",
    "col_digits = {'colsample_bytree': 3, 'learning_rate': 3, 'max_depth':0, 'min_child_samples':0,\n",
    "       'num_leaves':0, 'reg_alpha':3, 'reg_lambda':3, 'subsample':3}\n",
    "int_cols = ['Features', 'max_depth', 'min_child_samples', 'num_leaves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a392644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cw_string(s):\n",
    "    cleaned = re.sub(r\"np\\.float64\\(([^)]+)\\)\", r\"\\1\", s)\n",
    "    return ast.literal_eval(cleaned)\n",
    "\n",
    "def round_dec(val, d=2):\n",
    "    return round(val, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b2fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_tabular(tabular):\n",
    "    tabular = r\"\"\"\\hline\n",
    "\"\"\" + tabular\n",
    "    tabular = tabular.replace(r\"\\\\\", r\"\\\\ \\hline\")\n",
    "    to_repl = [r'\\toprule', r'\\midrule', r'\\bottomrule']\n",
    "    for s in to_repl:\n",
    "        tabular = tabular.replace(s, \"\")\n",
    "    return tabular\n",
    "        \n",
    "def build_supp_table(title: str, tabular: str, caption: str, n=None) -> str:\n",
    "    \"\"\"\n",
    "    Build a supplementary-materials table:\n",
    "\n",
    "    \\paragraph*{SN Table.}{\\bf TITLE}\n",
    "        \\label{SN-Table}\n",
    "        \\begin{table}[!ht]\n",
    "            \\centering\n",
    "    LATEX_TABLE\n",
    "        \\end{table}\n",
    "    CAPTION\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n=\"\"\n",
    "    tabular = clean_tabular(tabular)\n",
    "\n",
    "    return (\n",
    "        rf\"\\paragraph*{{S{n} Table.}}{{\\bf {title}}}\" \"\\n\"\n",
    "        rf\"\\label{{S{n}-Table}}\" \"\\n\"\n",
    "        r\"\\begin{table}[!ht]\" \"\\n\"\n",
    "        r\"    \\centering\" \"\\n\"\n",
    "        f\"{tabular}\\n\"\n",
    "        r\"\\end{table}\" \"\\n\"\n",
    "        f\"{caption}\"\n",
    "    )\n",
    "\n",
    "def build_main_table(title, latex_table, caption, label):\n",
    "    \"\"\"\n",
    "    Construct a LaTeX table environment with consistent structure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    title : str\n",
    "        Title displayed in bold in the caption.\n",
    "    latex_table : str\n",
    "        The tabular environment as a LaTeX string.\n",
    "    caption : str\n",
    "        Additional caption text placed under the table.\n",
    "    label : str\n",
    "        Label name (without 'tab:').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Full LaTeX table environment string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Clean unwanted booktabs commands\n",
    "    latex_table = clean_tabular(latex_table)\n",
    "\n",
    "    # Build final LaTeX table\n",
    "    table = f\"\"\"\n",
    "\\\\begin{{table}}[!ht]\n",
    "\\\\centering\n",
    "\\\\caption{{\\\\bf {title}}}\n",
    "{latex_table}\n",
    "\n",
    "\\\\begin{{flushleft}}{caption}\\\\end{{flushleft}}\n",
    "\\\\label{{tab:{label}}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "    return table.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f159b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_filepath = f\"../../Publication_Outputs/1_Thread_Start/metrics/table_metrics.xlsx\"\n",
    "mcc_dfs = []\n",
    "for sub in SUBREDDIT_LABELS:\n",
    "\n",
    "    df = pd.read_excel(eval_filepath, sheet_name=f\"{sub}_test\").rename(columns={\"n_feats\": \"Features\"})\n",
    "\n",
    "    mcc_df = df[['Features']].copy()\n",
    "    mcc_df[\"MCC\"] = df[\"MCC\"].map(lambda x: f\"{x:.4f}\") + \" \" + df[\"MCC CI\"].astype(str)\n",
    "\n",
    "    mcc_df = mcc_df.set_index(\"Features\")\n",
    "\n",
    "    mcc_dfs.append(mcc_df[['MCC']].rename(columns={\"MCC\": f\"{SUBREDDIT_LABELS[sub]}\"}))\n",
    "\n",
    "mcc_df = pd.concat(mcc_dfs, axis=1).reset_index()\n",
    "\n",
    "latex_str = mcc_df.to_latex(\n",
    "    index=False,                    # don’t print the row index\n",
    "    header=True,\n",
    "    float_format=\"%.4f\",\n",
    "    column_format=\"|l|r|r|r|\",      # LaTeX alignment (1 left + 8 right)\n",
    "    escape=True                    # so underscores in col names are not escaped weirdly\n",
    ")\n",
    "\n",
    "caption = r\"Test-set MCC values (with 95\\% bootstrap confidence intervals) for the tuned thread-start classifiers across the three subreddits. Each row corresponds to a model trained using the top-$n$ features. Higher MCC indicates better discrimination between classes.\"\n",
    "title = f\"Test-set MCC for the thread-start prediction models.\"\n",
    "full_latex = build_supp_table(title, latex_str, caption)\n",
    "# Save to file\n",
    "with open(f\"../../Publication_Outputs/1_Thread_Start/metrics/test_mccs.txt\", \"w\") as f:\n",
    "    f.write(full_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f666c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185827/3239559225.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s1_mods[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s1_mods[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s1_mods[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s1_mods[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s1_mods[sub]\n",
      "/tmp/ipykernel_185827/3239559225.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s1_mods[sub]\n"
     ]
    }
   ],
   "source": [
    "s1_mods = load_selected_models(Path(\"../../Publication_Outputs/1_Thread_Start/s1_mods.txt\"))\n",
    "eval_filepath = f\"../../Publication_Outputs/1_Thread_Start/metrics/table_metrics.xlsx\"\n",
    "rows = []\n",
    "for sub in SUBREDDIT_LABELS:\n",
    "\n",
    "    df = pd.read_excel(eval_filepath, sheet_name=f\"{sub}_test\").rename(columns={\"n_feats\": \"Features\"})\n",
    "    df = df.set_index(\"Features\")\n",
    "    metric_cols = [c for c in df.columns if \"CI\" not in c]\n",
    "    new_df = df[metric_cols].copy()\n",
    "    for col in metric_cols:\n",
    "        new_df[col] = df[col].map(lambda x: f\"{x:.4f}\") + \" \" + df[f\"{col} CI\"].astype(str)\n",
    "    \n",
    "    mod_row = new_df.iloc[s1_mods[sub]-1,:]\n",
    "    mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
    "    mod_row['Features'] = s1_mods[sub]\n",
    "    rows.append(mod_row)\n",
    "\n",
    "df = pd.concat(rows, axis=1)\n",
    "# --- Replace column headers with subreddit names ---\n",
    "subreddit_names = df.loc[\"Subreddit\"].tolist()\n",
    "df.columns = subreddit_names\n",
    "\n",
    "# --- Move 'Features' row to top ---\n",
    "features_row = df.loc[\"Features\"].to_frame().T\n",
    "\n",
    "# Drop Subreddit + Features rows\n",
    "df = df.drop([\"Subreddit\", \"Features\"])\n",
    "\n",
    "# Insert Features at top\n",
    "df = pd.concat([features_row, df])\n",
    "\n",
    "\n",
    "tabular = df.to_latex(\n",
    "    index=True,                    # don’t print the row index\n",
    "    header=True,\n",
    "    float_format=\"%.4f\",\n",
    "    column_format=\"|l|r|r|r|\",      # LaTeX alignment (1 left + 8 right)\n",
    "    escape=True                    # so underscores in col names are not escaped weirdly\n",
    ")\n",
    "\n",
    "caption = r\"The thread start model test set MCC, AUC, F1 score, balanced accuracy, and stalled started precision and recall scores with their corresponding 95\\% confidence intervals computed with 1000 bootstrap resamples.\"\n",
    "title = f\"Test set performance of the selected thread start models for each subreddit\"\n",
    "full_latex = build_main_table(title, tabular, caption, 's1-mods')\n",
    "# Save to file\n",
    "with open(f\"../../Publication_Outputs/1_Thread_Start/metrics/selected_mods.txt\", \"w\") as f:\n",
    "    f.write(full_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9adf155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_dfs = {}\n",
    "sheet_name = \"all_hyperparams\"\n",
    "for subreddit in SUBREDDIT_LABELS:\n",
    "    eval_filepath = f\"../../Outputs/1_thread_start/{subreddit}/4_model/evaluation.xlsx\"\n",
    "    df = pd.read_excel(eval_filepath, sheet_name=sheet_name)\n",
    "    \n",
    "    # Ensure correct column names\n",
    "    df.columns = [\"Features\", \"Parameter\", \"Value\"]\n",
    "\n",
    "    # Forward-fill N_feats to propagate block identifiers\n",
    "    df[\"Features\"] = df[\"Features\"].ffill().astype(int)\n",
    "\n",
    "    # Pivot into the desired wide format\n",
    "    table = df.pivot(index=\"Features\", columns=\"Parameter\", values=\"Value\")\n",
    "    for col in table.columns:\n",
    "        table[col] = table[col].apply(round_dec, d=col_digits[col])\n",
    "    for col in [x for x in table.columns if x in int_cols]:\n",
    "        table[col] = table[col].astype(int)\n",
    "    hyperparam_dfs[subreddit] = table.copy()\n",
    "\n",
    "    table = table.reset_index()  # if N_feats was the index\n",
    "\n",
    "    latex_str = table.to_latex(\n",
    "        index=False,                    # don’t print the row index\n",
    "        header=True,\n",
    "        float_format=\"%.3f\",         # control float precision\n",
    "        column_format=\"|l|r|r|r|r|r|r|r|r|\",      # LaTeX alignment (1 left + 8 right)\n",
    "        #caption=f\"{SUBREDDIT_LABELS[subreddit]} tuned thread start LightGBM hyperparameters by number of features.\",\n",
    "        #label=f\"tab:s1-{subreddit}-hyperparams\",\n",
    "        escape=True                    # so underscores in col names are not escaped weirdly\n",
    "    )\n",
    "    \n",
    "    caption = f\"Optimal LightGBM tree hyperparameters selected via cross-validated Optuna/TPE search for each number of features for {SUBREDDIT_LABELS[subreddit]}. Values represent cross-fold aggregated hyperparameters, using the mode for integer parameters and the mean for continuous parameters. These configurations were used for the final thread start model evaluation.\"\n",
    "    title = f\"{subreddit} tuned thread start LightGBM hyperparameters by number of features.\"\n",
    "    full_latex = build_supp_table(title, latex_str, caption)\n",
    "    # Save to file\n",
    "    with open(f\"../../Publication_Outputs/1_Thread_Start/tuning_outputs/{subreddit}_hparams.txt\", \"w\") as f:\n",
    "        f.write(full_latex)\n",
    "\n",
    "outfile = f\"../../Publication_Outputs/1_Thread_Start/tuning_outputs/hyperparams.xlsx\"\n",
    "with pd.ExcelWriter(outfile) as writer:\n",
    "    for sub, df in hyperparam_dfs.items():\n",
    "        df.to_excel(writer, sheet_name=sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4dffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_threshold_dfs = {}\n",
    "sheet_name = \"all_params\"\n",
    "for subreddit in SUBREDDIT_LABELS:\n",
    "    eval_filepath = f\"../../Outputs/1_thread_start/{subreddit}/4_model/evaluation.xlsx\"\n",
    "    df = pd.read_excel(eval_filepath, sheet_name=sheet_name)\n",
    "    \n",
    "    # Ensure correct column names\n",
    "    df.columns = [\"Features\", \"param_index\", \"Parameter\", \"Value\"]\n",
    "\n",
    "    # Forward-fill N_feats to propagate block identifiers\n",
    "    df[\"Features\"] = df[\"Features\"].ffill().astype(int)\n",
    "\n",
    "    # Pivot into the desired wide format\n",
    "    table = df.pivot(index=\"Features\", columns=\"Parameter\", values=\"Value\")\n",
    "\n",
    "    model_threshold_dfs[subreddit] = table.copy()[['model_threshold']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23bcd5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(model_threshold_dfs, axis=1).to_csv(f\"../../Publication_Outputs/1_Thread_Start/metrics/model_thresholds.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce70b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_cw_dfs = {}\n",
    "sheet_name = \"params\"\n",
    "for subreddit in SUBREDDIT_LABELS:\n",
    "    eval_filepath = f\"../../Outputs/2_thread_size/{subreddit}/2_tuning/tuning_outputs.xlsx\"\n",
    "    df = pd.read_excel(eval_filepath, sheet_name=sheet_name)\n",
    "    \n",
    "    # Ensure correct column names\n",
    "    df = df[['n_feats', 'final_class_weights']].rename(columns={\n",
    "        \"final_class_weights\": \"cws\"\n",
    "    })\n",
    "\n",
    "    s2_cw_dfs[subreddit] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "905bb0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"Stalled\", \"Small\", \"Medium\", \"Large\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c89be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = f\"../../Publication_Outputs/2_Thread_Size/tuning_outputs/class_weights.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(outfile) as writer:\n",
    "    for sub, df in s2_cw_dfs.items():\n",
    "        expanded = pd.json_normalize(df[\"cws\"].apply(parse_cw_string))\n",
    "        df = df.join(expanded)[[\"n_feats\", 0,1,2,3]]\n",
    "        ratios = df[['n_feats']].copy()\n",
    "        for col in [0,1,2,3]:\n",
    "            ratios[CLASS_NAMES[col]] = df[col]/df[0]\n",
    "        ratios.to_excel(writer, index=False, sheet_name=sub)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddfa147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_feat_dfs = {}\n",
    "sheet_name = \"feature_importances\"\n",
    "for subreddit in SUBREDDIT_LABELS:\n",
    "    eval_filepath = f\"../../Outputs/2_thread_size/{subreddit}/2_tuning/tuning_outputs.xlsx\"\n",
    "    df = pd.read_excel(eval_filepath, sheet_name=sheet_name)\n",
    "    \n",
    "    # Ensure correct column names\n",
    "    df = df[['feature', 'mean_importance', 'mean_split', 'mean_gain']].rename(columns={\n",
    "        'feature': 'Feature',\n",
    "        'mean_importance': 'Scaled',\n",
    "        'mean_split': 'Split',\n",
    "        'mean_gain': 'Gain'\n",
    "    })\n",
    "    df['Feature'] = df['Feature'].apply(format_label)\n",
    "    df['Scaled'] = df[\"Scaled\"].apply(round_dec, d=4)\n",
    "    df['Split'] = df[\"Split\"].apply(round_dec, d=0)\n",
    "    df['Gain'] = df[\"Gain\"].apply(round_dec, d=0)\n",
    "\n",
    "    s2_feat_dfs[subreddit] = df\n",
    "\n",
    "outfile = f\"../../Publication_Outputs/2_Thread_Size/tuning_outputs/feature_importances.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(outfile) as writer:\n",
    "    for sub, df in s2_feat_dfs.items():\n",
    "        df.to_excel(writer, sheet_name=sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e896913",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../Publication_Outputs/2_Thread_Size/tuning_outputs/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "506329da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_dfs = {}\n",
    "sheet_name = \"hyperparams\"\n",
    "for subreddit in SUBREDDIT_LABELS:\n",
    "    eval_filepath = f\"../../Outputs/2_thread_size/{subreddit}/4_model/evaluation.xlsx\"\n",
    "    df = pd.read_excel(eval_filepath, sheet_name=sheet_name)\n",
    "    # Ensure correct column names\n",
    "    df.columns = [\"Parameter\", \"Value\", \"Features\"]\n",
    "    # Forward-fill N_feats to propagate block identifiers\n",
    "    df[\"Features\"] = df[\"Features\"].ffill().astype(int)\n",
    "\n",
    "    # Pivot into the desired wide format\n",
    "    table = df.pivot(index=\"Features\", columns=\"Parameter\", values=\"Value\")\n",
    "    for col in table.columns:\n",
    "        table[col] = table[col].apply(round_dec, d=col_digits[col])\n",
    "    for col in [x for x in table.columns if x in int_cols]:\n",
    "        table[col] = table[col].astype(int)\n",
    "    hyperparam_dfs[subreddit] = table.copy()\n",
    "\n",
    "    table = table.reset_index()  # if N_feats was the index\n",
    "    \n",
    "\n",
    "    latex_str = table.to_latex(\n",
    "        index=False,                    # don’t print the row index\n",
    "        header=True,\n",
    "        float_format=\"%.3f\",\n",
    "        column_format=\"|l|r|r|r|r|r|r|r|r|\",      # LaTeX alignment (1 left + 8 right)\n",
    "        #caption=f\"{SUBREDDIT_LABELS[subreddit]} tuned thread start LightGBM hyperparameters by number of features.\",\n",
    "        #label=f\"tab:s1-{subreddit}-hyperparams\",\n",
    "        escape=True                    # so underscores in col names are not escaped weirdly\n",
    "    )\n",
    "    \n",
    "    caption = f\"Optimal LightGBM tree hyperparameters selected via cross-validated Optuna/TPE search for each number of features for {SUBREDDIT_LABELS[subreddit]}. Values represent cross-fold aggregated hyperparameters, using the mode for integer parameters and the mean for continuous parameters. These configurations were used for the final thread size model evaluation.\"\n",
    "    title = f\"{SUBREDDIT_LABELS[subreddit]} tuned thread size LightGBM hyperparameters by number of features.\"\n",
    "    full_latex = build_supp_table(title, latex_str, caption)\n",
    "    # Save to file\n",
    "    with open(f\"../../Publication_Outputs/2_Thread_Size/tuning_outputs/{subreddit}_hparams.txt\", \"w\") as f:\n",
    "        f.write(full_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1952eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_filepath = f\"../../Publication_Outputs/2_Thread_Size/metrics/table_metrics.xlsx\"\n",
    "mcc_dfs = []\n",
    "for sub in SUBREDDIT_LABELS:\n",
    "\n",
    "    df = pd.read_excel(eval_filepath, sheet_name=f\"{sub}_test\").rename(columns={\"n_feats\": \"Features\"})\n",
    "\n",
    "    mcc_df = df[['Features']].copy()\n",
    "    mcc_df[\"MCC\"] = df[\"MCC\"].map(lambda x: f\"{x:.4f}\") + \" \" + df[\"MCC CI\"].astype(str)\n",
    "\n",
    "    mcc_df = mcc_df.set_index(\"Features\")\n",
    "\n",
    "    mcc_dfs.append(mcc_df[['MCC']].rename(columns={\"MCC\": f\"{SUBREDDIT_LABELS[sub]}\"}))\n",
    "\n",
    "mcc_df = pd.concat(mcc_dfs, axis=1).reset_index()\n",
    "\n",
    "latex_str = mcc_df.to_latex(\n",
    "    index=False,                    # don’t print the row index\n",
    "    header=True,\n",
    "    float_format=\"%.4f\",\n",
    "    column_format=\"|l|r|r|r|\",      # LaTeX alignment (1 left + 8 right)\n",
    "    escape=True                    # so underscores in col names are not escaped weirdly\n",
    ")\n",
    "\n",
    "caption = r\"Test-set MCC values (with 95\\% bootstrap confidence intervals) for the tuned thread-size classifiers across the three subreddits. Each row corresponds to a model trained using the top-$n$ features. Higher MCC indicates better discrimination between classes.\"\n",
    "title = f\"Test-set MCC for the thread-size prediction models.\"\n",
    "full_latex = build_supp_table(title, latex_str, caption)\n",
    "# Save to file\n",
    "with open(f\"../../Publication_Outputs/2_Thread_Size/metrics/test_mccs.txt\", \"w\") as f:\n",
    "    f.write(full_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfe12dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185827/2292598750.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s2_mods[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s2_mods[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s2_mods[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s2_mods[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s2_mods[sub]\n",
      "/tmp/ipykernel_185827/2292598750.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mod_row['Features'] = s2_mods[sub]\n"
     ]
    }
   ],
   "source": [
    "s2_mods = load_selected_models(Path(\"../../Publication_Outputs/2_Thread_Size/s2_mods.txt\"))\n",
    "eval_filepath = f\"../../Publication_Outputs/2_Thread_Size/metrics/table_metrics.xlsx\"\n",
    "rows = []\n",
    "for sub in SUBREDDIT_LABELS:\n",
    "\n",
    "    df = pd.read_excel(eval_filepath, sheet_name=f\"{sub}_test\").rename(columns={\"n_feats\": \"Features\"})\n",
    "    df = df.set_index(\"Features\")\n",
    "    metric_cols = [c for c in df.columns if \"CI\" not in c]\n",
    "    new_df = df[metric_cols].copy()\n",
    "    for col in metric_cols:\n",
    "        new_df[col] = df[col].map(lambda x: f\"{x:.4f}\") + \" \" + df[f\"{col} CI\"].astype(str)\n",
    "    \n",
    "    mod_row = new_df.iloc[s2_mods[sub]-1,:]\n",
    "    mod_row['Subreddit'] = SUBREDDIT_LABELS[sub]\n",
    "    mod_row['Features'] = s2_mods[sub]\n",
    "    rows.append(mod_row)\n",
    "\n",
    "df = pd.concat(rows, axis=1)\n",
    "# --- Replace column headers with subreddit names ---\n",
    "subreddit_names = df.loc[\"Subreddit\"].tolist()\n",
    "df.columns = subreddit_names\n",
    "\n",
    "# --- Move 'Features' row to top ---\n",
    "features_row = df.loc[\"Features\"].to_frame().T\n",
    "\n",
    "# Drop Subreddit + Features rows\n",
    "df = df.drop([\"Subreddit\", \"Features\"])\n",
    "\n",
    "# Insert Features at top\n",
    "df = pd.concat([features_row, df])\n",
    "\n",
    "\n",
    "tabular = df.to_latex(\n",
    "    index=True,                    # don’t print the row index\n",
    "    header=True,\n",
    "    float_format=\"%.4f\",\n",
    "    column_format=\"|l|r|r|r|\",      # LaTeX alignment (1 left + 8 right)\n",
    "    escape=True                    # so underscores in col names are not escaped weirdly\n",
    ")\n",
    "\n",
    "caption = r\"The thread size model test set MCC, AUC, F1 score, balanced accuracy, and stalled, small, medium and large precision and recall scores with their corresponding 95\\% confidence intervals computed with 1000 bootstrap resamples.\"\n",
    "title = f\"Test set performance of the selected thread size models for each subreddit\"\n",
    "full_latex = build_main_table(title, tabular, caption, 's2-mods')\n",
    "# Save to file\n",
    "with open(f\"../../Publication_Outputs/2_Thread_Size/metrics/selected_mods.txt\", \"w\") as f:\n",
    "    f.write(full_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf65ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2stagemodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
