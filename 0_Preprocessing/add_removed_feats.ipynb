{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54104074",
   "metadata": {},
   "source": [
    "Notebook to make X and Y files which go through steps in 3_model_data.py without removing any columns (for use when testing e.g. politics model on crypto data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0a08177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b0cb221",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_COL = \"thread_size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58b6bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_vals(y: pd.Series):\n",
    "    \"\"\"\n",
    "    Apply logarithmic transformation to target variable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : pd.Series\n",
    "        Target variable values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series or None\n",
    "        Log-transformed values, log(y+1) if min < 1, or None if negative values.\n",
    "    \"\"\"\n",
    "    if y.min() < 0:\n",
    "        print(f\"[INFO] Values are negative, not taking log.\")\n",
    "        return None\n",
    "    elif y.min() < 1:\n",
    "        print(f\"[INFO] Min value < 1, taking log(y+1)\")\n",
    "        return np.log(y + 1)\n",
    "    else:\n",
    "        print(f\"[INFO] Taking log(y)\")\n",
    "        return np.log(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b78d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../../Outputs/3_trial_models/0_preprocessing\"\n",
    "\n",
    "os.makedirs(outdir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b6594e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Taking log(y)\n",
      "[INFO] Taking log(y)\n",
      "[INFO] Saving train dfs to\n",
      "../../Outputs/3_trial_models/0_preprocessing/conspiracy_train_X.parquet\n",
      "../../Outputs/3_trial_models/0_preprocessing/conspiracy_train_Y.parquet\n",
      "[INFO] Saving test dfs to\n",
      "../../Outputs/3_trial_models/0_preprocessing/conspiracy_test_X.parquet\n",
      "../../Outputs/3_trial_models/0_preprocessing/conspiracy_test_Y.parquet\n",
      "[INFO] Taking log(y)\n",
      "[INFO] Taking log(y)\n",
      "[INFO] Saving train dfs to\n",
      "../../Outputs/3_trial_models/0_preprocessing/crypto_train_X.parquet\n",
      "../../Outputs/3_trial_models/0_preprocessing/crypto_train_Y.parquet\n",
      "[INFO] Saving test dfs to\n",
      "../../Outputs/3_trial_models/0_preprocessing/crypto_test_X.parquet\n",
      "../../Outputs/3_trial_models/0_preprocessing/crypto_test_Y.parquet\n",
      "[INFO] Taking log(y)\n",
      "[INFO] Taking log(y)\n",
      "[INFO] Saving train dfs to\n",
      "../../Outputs/3_trial_models/0_preprocessing/politics_train_X.parquet\n",
      "../../Outputs/3_trial_models/0_preprocessing/politics_train_Y.parquet\n",
      "[INFO] Saving test dfs to\n",
      "../../Outputs/3_trial_models/0_preprocessing/politics_test_X.parquet\n",
      "../../Outputs/3_trial_models/0_preprocessing/politics_test_Y.parquet\n"
     ]
    }
   ],
   "source": [
    "x_test_dfs = {}\n",
    "for sub in ['conspiracy', 'crypto', 'politics']:\n",
    "    preprocessing_dir = f\"../../Outputs/0_preprocessing/{sub}\"\n",
    "    data = {}\n",
    "    for d in [\"train\", \"test\"]:\n",
    "        data[d] = pd.read_parquet(f\"{preprocessing_dir}/tf-idf/{sub}_svd_enriched_{d}_data.parquet\")\n",
    "        for col in [\"author\", \"domain\"]:\n",
    "            freq = data[\"train\"][col].astype(str).value_counts(normalize=True)\n",
    "            for k, df in data.items():\n",
    "                df[f\"{col}_freq\"] = (\n",
    "                    df[col].astype(str).map(freq).fillna(0.0).astype(\"float32\")\n",
    "                )\n",
    "    y_col = Y_COL\n",
    "    for k, df in data.items():\n",
    "            log_y_col = log_vals(df[Y_COL])\n",
    "            if log_y_col is not None:\n",
    "                df[f\"log_{Y_COL}\"] = log_y_col\n",
    "                y_col = f\"log_{Y_COL}\"\n",
    "    x_dfs = {}\n",
    "    y_dfs = {}\n",
    "    for i, df in data.items():\n",
    "        x_dfs[i] = df[[x for x in df.columns if x!=y_col]]\n",
    "        y_dfs[i] = df[[y_col]]\n",
    "    \n",
    "    x_test_dfs[sub] = x_dfs['test']\n",
    "    for k, x_df in x_dfs.items():\n",
    "        x_out = f\"{outdir}/{sub}_{k}_X.parquet\"\n",
    "        y_out = f\"{outdir}/{sub}_{k}_Y.parquet\"\n",
    "        print(f\"[INFO] Saving {k} dfs to\\n{x_out}\\n{y_out}\")\n",
    "        x_df.to_parquet(x_out)\n",
    "        y_dfs[k].to_parquet(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffbe1bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['authors', 'author', 'author_freq']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in x_test_dfs['crypto'].columns if \"author\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036fd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2stagemodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
